{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %pylab inline\n",
    "#start a timer\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#import operating system \n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "#To Show Images\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "from nilearn import plotting\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Import Pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torch_similarity.modules import NormalizedCrossCorrelation\n",
    "import pytorch_ssim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "#Import Generator, Discriminator, Encoder and Code Discriminator \n",
    "from mmGANBased3 import *\n",
    "\n",
    "#Monai (Import data and transform data)\n",
    "from monai.transforms import \\\n",
    "    Compose,Flip, AddChannel,ResizeWithPadOrCrop, ScaleIntensity, ToTensor, Resize, RandRotate, RandFlip, RandScaleIntensity, RandZoom, RandGaussianNoise, RandAffine\n",
    "from monai.data import CacheDataset, ImageDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose architecture\n",
    "α-WGANSigmaRat1 => arch1\n",
    "\n",
    "α-WGANSigmaRat2 => arch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#architecture = \"arch1\"\n",
    "architecture = \"arch2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Generator, Discriminator, Encoder and Code Discriminator \n",
    "if architecture == \"arch1\":\n",
    "    from WGAN_SigmaRat1 import *\n",
    "if architecture == \"arch2\":\n",
    "    from WGAN_SigmaRat2 import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_______________________________________________Constants_______________________________________________\n",
    "DEBUG=True\n",
    "PATH_DATASET = 'path/to/the/dataset/MRI/'\n",
    "PATH_DATASET = '../../../datasets/sigmaRat/mri/'#_---------------------------------------------------------------------------\n",
    "MODEL_NAME=\"Model_Name\"\n",
    "\n",
    "#Neural net\n",
    "BATCH_SIZE = 2 #it must be 2 because of some metrics \n",
    "WORKERS = 2\n",
    "\n",
    "#setting latent variable sizes\n",
    "LATENT_DIM = 500\n",
    "\n",
    "#_________________________Visualization_variables_________________________\n",
    "SEE_SEVERAL_MODELS=True\n",
    "SEE_SLICE_SERIES=True\n",
    "USE_MONAI=True\n",
    "\n",
    "#__________________________f_it_is_to_calculate___________________________\n",
    "CALC_MS_SSIM=True\n",
    "CALC_MMD_SCORE=True\n",
    "CALC_PSNR=True\n",
    "CALC_RMSE=True\n",
    "CALC_MAE=True\n",
    "CALC_NCC=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Set Creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_loader():\n",
    "    train_transforms = Compose([AddChannel(),\n",
    "                                \n",
    "                                ScaleIntensity(minv=0, maxv=1.0),\n",
    "                                ResizeWithPadOrCrop(spatial_size =(64, 64, 64), mode='constant'),\n",
    "                                ToTensor()])\n",
    "\n",
    "    train_ds = ImageDataset(image_files=train_dataset, transform=train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, pin_memory=torch.cuda.is_available())\n",
    "    return(train_loader)\n",
    "\n",
    "def create_train_dataset_list(path_dataset):\n",
    "    dataset = [f for f in listdir(path_dataset) if isfile(join(path_dataset, f))]\n",
    "    train_dataset=list()\n",
    "    for i in dataset:\n",
    "        train_dataset.append(path_dataset+i)\n",
    "    return train_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_train_dataset_list(PATH_DATASET)\n",
    "train_loader=create_train_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nets(only_G, number):\n",
    "    if only_G:\n",
    "        G = Generator(noise = LATENT_DIM)\n",
    "        #G.cuda()\n",
    "        device = torch.device('cpu')\n",
    "        G.load_state_dict(torch.load('./checkpoint/'+MODEL_NAME+'/G_iter'+str(number)+'.pth'))\n",
    "        #G.cuda()\n",
    "        return (G)\n",
    "    else:\n",
    "        G = Generator(noise = LATENT_DIM)\n",
    "        CD = Code_Discriminator(code_size = LATENT_DIM ,num_units = 4096)\n",
    "        D = Discriminator(is_dis=True)\n",
    "        if architecture == \"arch1\":\n",
    "            E = Discriminator(out_class = LATENT_DIM,is_dis=False)\n",
    "        if architecture == \"arch2\":\n",
    "            E = Encoder(out_class = LATENT_DIM,is_dis=False)\n",
    "        '''\n",
    "        # __TO_GPU___\n",
    "        E.cuda()   #|\n",
    "        G.cuda()   #|\n",
    "        CD.cuda()  #|\n",
    "        D.cuda()   #|\n",
    "        #__________#|\n",
    "        '''\n",
    "        \n",
    "        G.load_state_dict(torch.load('./checkpoint/'+MODEL_NAME+'/G_iter'+str(number)+'.pth'))\n",
    "        CD.load_state_dict(torch.load('./checkpoint/'+MODEL_NAME+'/CD_iter'+str(number)+'.pth'))\n",
    "        E.load_state_dict(torch.load('./checkpoint/'+MODEL_NAME+'/E_iter'+str(number)+'.pth'))\n",
    "        D.load_state_dict(torch.load('./checkpoint/'+MODEL_NAME+'/D_iter'+str(number)+'.pth'))\n",
    "\n",
    "        return (G,CD,D,E)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affine(origin):\n",
    "    scan = nib.load(origin)\n",
    "    affine=scan.affine\n",
    "    header=scan.header\n",
    "\n",
    "    return affine, header\n",
    "\n",
    "def saver(image, origin, name, model_name):\n",
    "    affine, header=get_affine(origin)\n",
    "    \n",
    "    if not os.path.exists(model_name):\n",
    "        Path(model_name).mkdir(parents=True, exist_ok=True)\n",
    "    feat = np.squeeze((image).data.cpu().numpy())\n",
    "    feat = feat[:,:,12:52]\n",
    "    feat = nib.Nifti1Image(feat, affine = affine, header = header)\n",
    "    nib.save(feat, model_name + \"/\" + name + \".nii\")\n",
    "    \n",
    "    return (\"File \"+ name + \" saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(image, reality):\n",
    "    #Show the real image\n",
    "    #image=rescale_array(image,0,1)\n",
    "    feat = np.squeeze((image[0]).data.cpu().numpy())\n",
    "    #feat=np.fliplr(feat)\n",
    "    feat = nib.Nifti1Image(feat,affine = np.eye(4))\n",
    "    plotting.plot_img(feat,title=reality, annotate=False, draw_cross=False, black_bg=True)\n",
    "    plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = next(iter(train_loader)) #next image\n",
    "visualization(image=real_images,  reality=\"Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_array(arr: np.ndarray, minv: float = 0.0, maxv: float = 1.0): #monmai function adapted\n",
    "    \"\"\"\n",
    "    Rescale the values of numpy array `arr` to be from `minv` to `maxv`.\n",
    "    \"\"\"\n",
    "\n",
    "    mina = torch.min(arr)\n",
    "    maxa = torch.max(arr)\n",
    "\n",
    "    if mina == maxa:\n",
    "        return arr * minv\n",
    "\n",
    "    norm = (arr - mina) / (maxa - mina)  # normalize the array first\n",
    "    return (norm * (maxv - minv)) + minv  # rescale by minv and maxv, which is the normalized array by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nets(only_G=True, number=200000)\n",
    "z_rand = Variable(torch.randn((BATCH_SIZE,LATENT_DIM)),volatile=True) #random vector\n",
    "x_rand = G(z_rand)# Image Generation\n",
    "x_rand=rescale_array(x_rand)\n",
    "visualization(x_rand, \"Fake\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice series visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_series(display_mode='x', arr1=list(), arr2=list(), show_color=True,show_real=False,model_number=163000):\n",
    "    G=nets(only_G=True, number=model_number)\n",
    "    z_rand = Variable(torch.randn((BATCH_SIZE,LATENT_DIM)),volatile=True) #random vector\n",
    "    x_rand = G(z_rand)\n",
    "    x_rand=rescale_array(x_rand,0,1)\n",
    "\n",
    "    if show_real:\n",
    "        real_images = next(iter(train_loader)) #next image\n",
    "        feat = np.squeeze((real_images[0]).data.cpu().numpy())\n",
    "        feat=np.fliplr(feat)\n",
    "        feat = nib.Nifti1Image(feat,affine = np.eye(4))\n",
    "        print(\"###########################################################\")\n",
    "        print(\"#####################---REAL_Slices---#####################\")\n",
    "        print(\"###########################################################\")\n",
    "        if show_color:\n",
    "            #first row\n",
    "            disp = plotting.plot_img(feat,cut_coords=arr1,draw_cross=False,annotate=False,black_bg=True,display_mode=display_mode)\n",
    "            plotting.show()\n",
    "            #second row\n",
    "            disp=plotting.plot_img(feat,cut_coords=arr2,draw_cross=False,annotate=False,black_bg=True,display_mode=display_mode)\n",
    "            plotting.show()\n",
    "        else:\n",
    "            #first row\n",
    "            disp = plotting.plot_anat(feat,cut_coords=arr1,draw_cross=False,annotate=False,black_bg=True,display_mode=display_mode)\n",
    "            plotting.show()\n",
    "            #second row\n",
    "            disp=plotting.plot_anat(feat,cut_coords=arr2,draw_cross=False,annotate=False,black_bg=True,display_mode=display_mode)\n",
    "            plotting.show()\n",
    "    print(\"###########################################################\")\n",
    "    print(\"#####################---FAKE_Slices---#####################\")\n",
    "    print(\"###########################################################\")\n",
    "    feat = np.squeeze((x_rand[0]).data.cpu().numpy())\n",
    "    feat=np.fliplr(feat)\n",
    "    feat = nib.Nifti1Image(feat,affine = np.eye(4))\n",
    "    if show_color:\n",
    "        #first row\n",
    "        disp = plotting.plot_img(feat,cut_coords=arr1,draw_cross=False,annotate=False,black_bg=True,display_mode=display_mode)\n",
    "        plotting.show()\n",
    "        #second row\n",
    "        disp=plotting.plot_img(feat,cut_coords=arr2,draw_cross=False,annotate=False,black_bg=True,display_mode=display_mode)\n",
    "        plotting.show()\n",
    "        \n",
    "        disp = plotting.plot_img(feat,cut_coords=arr1,draw_cross=False,annotate=False,black_bg=True,display_mode='x')\n",
    "        plotting.show()\n",
    "        #second row\n",
    "        disp=plotting.plot_img(feat,cut_coords=arr2,draw_cross=False,annotate=False,black_bg=True,display_mode='x')\n",
    "        plotting.show()\n",
    "        \n",
    "        disp = plotting.plot_img(feat,cut_coords=arr1,draw_cross=False,annotate=False,black_bg=True,display_mode='y')\n",
    "        plotting.show()\n",
    "        #second row\n",
    "        disp=plotting.plot_img(feat,cut_coords=arr2,draw_cross=False,annotate=False,black_bg=True,display_mode='y')\n",
    "        plotting.show()\n",
    "    else:\n",
    "        #first row\n",
    "        disp = plotting.plot_anat(feat,cut_coords=arr1,draw_cross=False,annotate=False,black_bg=True,display_mode=display_mode)\n",
    "        plotting.show()\n",
    "        #second row\n",
    "        disp=plotting.plot_anat(feat,cut_coords=arr2,draw_cross=False,annotate=False,black_bg=True,display_mode=display_mode)\n",
    "        plotting.show()\n",
    "        \n",
    "        disp = plotting.plot_anat(feat,cut_coords=arr1,draw_cross=False,annotate=False,black_bg=True,display_mode='x')\n",
    "        plotting.show()\n",
    "        #second row\n",
    "        disp=plotting.plot_anat(feat,cut_coords=arr2,draw_cross=False,annotate=False,black_bg=True,display_mode='x')\n",
    "        plotting.show()\n",
    "        \n",
    "        disp = plotting.plot_anat(feat,cut_coords=arr1,draw_cross=False,annotate=False,black_bg=True,display_mode='y')\n",
    "        plotting.show()\n",
    "        #second row\n",
    "        disp=plotting.plot_anat(feat,cut_coords=arr2,draw_cross=False,annotate=False,black_bg=True,display_mode='y')\n",
    "        plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#______________set_slices_to_see____________________\n",
    "#arr1 = [4,6,8,10,12,14,16,18,20,22,24,26,28,30,32] #Every values between 1 and 64\n",
    "#arr2 = [34,36,38,40,42,44,46,48,50,52,54,56,58,60] #|\n",
    "#___________________________________________________|\n",
    "\n",
    "     #______________set_slices_to_see____________________\n",
    "arr1 = [22,24,26,28,30] #Every values must be between 1 and 64\n",
    "arr2 = [32,34,36,38,40] #|\n",
    "#____________________________________\n",
    "\n",
    "#_________________________which_types_of_slices_______________________ \n",
    "display_mode='z' #it could be 'x'->sagital ,'y'->coronal or 'z'->axial\n",
    "\n",
    "show_color=False #Anatomical plot (False) or colored plot (True)\n",
    "show_real=False #If want to see the real image (set True to see)\n",
    "model_number= 200000 #Set the model number for the Generator\n",
    "\n",
    "for i in range(20):\n",
    "\n",
    "    slice_series(display_mode=display_mode,arr1=arr1,arr2=arr2, show_color=show_color,show_real=show_real,model_number=model_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "<a id=\"Metrics\">  </a>\n",
    "# Metrics - Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiscale Structural Similarity Index Measure (MS-SSIM)\n",
    "# $ SSIM(x,y)=\\frac{(2\\mu_{x}\\mu_{y}+c_{1})(2\\sigma_{xy}+c_{2})}{(\\mu_{x}^{2} +\\mu_{y}^{2}+c_{1})(\\sigma_{x}^{2} +\\sigma_{y}^{2}+c_{2})} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_ssim_real(number=20):\n",
    "    meanarr = list()\n",
    "    contar=0\n",
    "    for k in range(number):\n",
    "        sum_ssim=0\n",
    "        for i,dat in enumerate(train_loader):\n",
    "            if len(dat)!=2:\n",
    "                break\n",
    "            img1 = dat[0]\n",
    "            img2 = dat[1]\n",
    "            \n",
    "            img1=rescale_array(img1, 0.0, 1.0)\n",
    "            img2=rescale_array(img2, 0.0, 1.0)\n",
    "            \n",
    "            img1 = img1[:,:,:,12:52]\n",
    "            img2 = img2[:,:,:,12:52]\n",
    "            \n",
    "            msssim = pytorch_ssim.msssim_3d(img1,img2)\n",
    "            sum_ssim = sum_ssim+msssim\n",
    "            contar+=1\n",
    "        meanarr.append(sum_ssim/(i+1))\n",
    "        \n",
    "    visualization(image=dat[:,:,:,:,12:52], reality=\"Real\")\n",
    "    print(contar)\n",
    "    meanarr2=torch.tensor(meanarr)\n",
    "    return('Total_mean:'+str(torch.mean(meanarr2).item())+' STD:'+str(torch.std(meanarr2).item()))\n",
    "\n",
    "    \n",
    "def ms_ssim_generated(number=1750):\n",
    "    meanarr = list()\n",
    "    sum_ssim=0\n",
    "    contar=0\n",
    "    for i in range(number):\n",
    "        noise = Variable(torch.randn((2, 1000)).cuda())\n",
    "        fake_image = G(noise)\n",
    "        \n",
    "        img1 = fake_image[0]\n",
    "        img2 = fake_image[1]\n",
    "        \n",
    "        img1 = rescale_array(img1, 0.0, 1.0)\n",
    "        img2 = rescale_array(img2, 0.0, 1.0)\n",
    "        \n",
    "        img1 = img1[:,:,:,12:52]\n",
    "        img2 = img2[:,:,:,12:52]\n",
    "\n",
    "        msssim = pytorch_ssim.msssim_3d(img1,img2)\n",
    "        contar+=1\n",
    "        sum_ssim = sum_ssim+msssim\n",
    "        meanarr.append(sum_ssim/(i+1))\n",
    "    print(contar)\n",
    "    visualization(image=fake_image[:,:,:,:,12:52], reality=\"Fake\")\n",
    "\n",
    "    meanarr2=torch.tensor(meanarr)\n",
    "    \n",
    "    return('Total_mean:'+str(torch.mean(meanarr2).item())+' STD:'+str(torch.std(meanarr2).item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CALC_MS_SSIM:\n",
    "    number=200\n",
    "    model_number=200000 #Set the model number for the Generator\n",
    "    G=nets(only_G=True, number=model_number).cuda()\n",
    "    print(\"#####################---REAL_Images---#####################\")\n",
    "    print(\"MS_SSIM_real=\",ms_ssim_real(number//10)) #will do 1750 comparations\n",
    "    print(\"#####################---FAKE_Images---#####################\")\n",
    "    print(\"MS_SSIM_fake=\",ms_ssim_generated(int(number*8.75))) #the same as previous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Maximum-Mean Discrepancy Score (MMD Score)\n",
    "# $ MMD(P,Q)=||\\mu _{P}-\\mu _{Q}||_{H} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmd_score(number=100):     \n",
    "    meanarr = list()\n",
    "    for s in range(number):\n",
    "        distmean = 0.0\n",
    "        for i,(y) in enumerate(train_loader):\n",
    "            y = Variable(y).cuda()\n",
    "            y = rescale_array(y, 0.0, 1.0)\n",
    "            y = y[:,:,:,:,12:52]\n",
    "\n",
    "            z_rand = Variable(torch.randn((BATCH_SIZE,LATENT_DIM)),volatile=True).cuda() #random vector\n",
    "            x = G(z_rand)\n",
    "            x = rescale_array(x, 0.0, 1.0)\n",
    "            x = x[:,:,:,:,12:52]\n",
    "\n",
    "            \n",
    "            B = y.size(0)\n",
    "            x = torch.reshape(x, (x.size(0), x.size(2) * x.size(3)* x.size(4)))\n",
    "            #x = x.view(x.size(0), x.size(2) * x.size(3)* x.size(4))\n",
    "            #y = y.view(y.size(0), y.size(2) * y.size(3)* y.size(4))\n",
    "            y = torch.reshape(y, (y.size(0), y.size(2) * y.size(3)* y.size(4)))\n",
    "            \n",
    "            xx, yy, zz = torch.mm(x,x.t()), torch.mm(y,y.t()), torch.mm(x,y.t())\n",
    "\n",
    "            beta = (1./(B*B))\n",
    "            gamma = (2./(B*B)) \n",
    "\n",
    "            Dist = beta * (torch.sum(xx)+torch.sum(yy)) - gamma * torch.sum(zz)\n",
    "            Dist2=Dist.item()\n",
    "            distmean += Dist2\n",
    "\n",
    "\n",
    "        #print('Mean:'+str(distmean/(i+1)))\n",
    "        meanarr.append(distmean/(i+1))\n",
    "\n",
    "    meanarr2=torch.tensor(meanarr)\n",
    "\n",
    "    return('Total_mean:'+str(torch.mean(meanarr2).item())+' STD:'+str(torch.std(meanarr2).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CALC_MMD_SCORE:\n",
    "    number=100\n",
    "    model_number=200000 #Set the model number for the Generator\n",
    "    G=nets(only_G=True, number=model_number).cuda()\n",
    "    print(\"#####################---MMD_Score---#####################\")\n",
    "    print(\"MMD=\",mmd_score(number=number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Peak signal-to-noise ratio (PSNR) \n",
    "\n",
    "$ PSNR = 20\\cdot log_{10}(MAXRange)-10\\cdot log_{10}(MSE) $\n",
    "\n",
    "If normalized values are used $ 20\\cdot log_{10}(MAXRange)$ will be zero so:\n",
    "\n",
    "# $ PSNR = 10\\cdot log_{10}(MSE) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_mse = nn.MSELoss()\n",
    "def PSNR(value_range=1, model_number=200000,number=100):\n",
    "    meanarr=list()\n",
    "\n",
    "    #verify if the values are between 0 and 1\n",
    "    value_range=torch.cuda.FloatTensor([[value_range]])\n",
    "    #print(value_range)\n",
    "    for s in range(number):\n",
    "        semi_psnr=0.0\n",
    "        for i,(y) in enumerate(train_loader):\n",
    "            y = Variable(y).cuda()\n",
    "            \n",
    "            y = y[:,:,:,:,12:52]\n",
    "\n",
    "            #y=((y+1)/2) #normalization [0,1]\n",
    "            y = rescale_array(y, 0.0, 1.0)\n",
    "            \n",
    "            z_rand = Variable(torch.randn((2,LATENT_DIM)),volatile=True).cuda() #random vector\n",
    "            x_rand = G(z_rand)\n",
    "            x_rand = x_rand[:,:,:,:,12:52]\n",
    "\n",
    "            \n",
    "            #x_rand=((x_rand+1)/2) #normalization [0,1]\n",
    "            x_rand = rescale_array(x_rand, 0.0, 1.0)\n",
    "\n",
    "            PSNR = 20.*torch.log10(value_range) - 10.*torch.log10(criterion_mse(x_rand, y))\n",
    "            PSNR2=PSNR.item()\n",
    "            semi_psnr+=PSNR2\n",
    "        #print('Mean:'+str(semi_psnr/(i+1)))\n",
    "        meanarr.append(semi_psnr/(i+1))\n",
    "    meanarr2=torch.tensor(meanarr)\n",
    "\n",
    "    \n",
    "    return('Total_mean:'+str(torch.mean(meanarr2).item())+' STD:'+str(torch.std(meanarr2).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CALC_PSNR:  \n",
    "    number=100\n",
    "    model_number=200000\n",
    "    G=nets(only_G=True, number=model_number).cuda()\n",
    "    print(\"#####################---PSNR_Value---#####################\")\n",
    "    print(\"PSNR=\",PSNR(number=number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Root Mean Squared Error\n",
    "$ MSE(P,Q)=\\frac{1}{n}\\sum_{i=1}^{n}(y_{i}-x_{i})^{2} $\n",
    "# $ RMSE=\\sqrt{MSE} $\n",
    "#### NRMSE can be calculated by $ RMSE/(max-min) $ -> since max=1 and min=0, $ NRMSE=RMSE $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(number=100):\n",
    "    mse = nn.MSELoss() #-> L2 Loss\n",
    "\n",
    "    meanarr=list()\n",
    "    for s in range(number):\n",
    "        semi_rmse=0.0\n",
    "        for i,(y) in enumerate(train_loader):\n",
    "\n",
    "            y = Variable(y).cuda()\n",
    "            y = y[:,:,:,:,12:52]\n",
    "            #y=((y+1)/2) #normalization [0,1]\n",
    "            y = rescale_array(y, 0.0, 1.0)\n",
    "\n",
    "            z_rand = Variable(torch.randn((1,LATENT_DIM)),volatile=True).cuda() #random vector\n",
    "            x_rand = G(z_rand) #prediction image\n",
    "            \n",
    "            x_rand = x_rand[:,:,:,:,12:52]\n",
    "            #x_rand=((x_rand+1)/2) #normalization [0,1]\n",
    "            x_rand = rescale_array(x_rand, 0.0, 1.0)\n",
    "\n",
    "            RMSE_value= torch.sqrt(mse(x_rand,y))\n",
    "\n",
    "            semi_rmse+=RMSE_value.item()\n",
    "        meanarr.append(semi_rmse/(i+1))    \n",
    "    meanarr2=torch.tensor(meanarr)\n",
    "    \n",
    "    return('Total_mean:'+str(torch.mean(meanarr2).item())+' STD:'+str(torch.std(meanarr2).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CALC_RMSE:\n",
    "    number=100\n",
    "    model_number=200000\n",
    "    G=nets(only_G=True, number=model_number).cuda()\n",
    "    print(\"#####################---RMSE/NRMSE_Value---#####################\")\n",
    "    print(\"RMSE=\",RMSE(number=number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Mean Absolute Error (MAE)\n",
    "# $ MAE=\\frac{\\sum_{i=1}^{n}|y_{i}-x_{i}| }{n} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(number=100):\n",
    "    mae = nn.L1Loss() #-> L1 Loss\n",
    "    meanarr=list()\n",
    "    \n",
    "    for s in range(number):\n",
    "        semi_mae=0.0\n",
    "        for i,(y) in enumerate(train_loader):\n",
    "            y = Variable(y).cuda()\n",
    "            y = rescale_array(y, 0.0, 1.0)\n",
    "            \n",
    "            #y=((y+1)/2) #normalization [0,1]\n",
    "\n",
    "            z_rand = Variable(torch.randn((1,LATENT_DIM)),volatile=True).cuda() #random vector\n",
    "            x_rand = G(z_rand) #prediction image\n",
    "            \n",
    "            x_rand = rescale_array(x_rand, 0.0, 1.0)\n",
    "            #x_rand=((x_rand+1)/2) #normalization [0,1]\n",
    "\n",
    "            MAE_value = mae(x_rand,y)\n",
    "\n",
    "            semi_mae+=MAE_value.item()\n",
    "        meanarr.append(semi_mae/(i+1))\n",
    "    meanarr2=torch.tensor(meanarr)\n",
    "    \n",
    "    return('Total_mean:'+str(torch.mean(meanarr2).item())+' STD:'+str(torch.std(meanarr2).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CALC_MAE:\n",
    "    number=100\n",
    "    model_number=200000\n",
    "    G=nets(only_G=True, number=model_number).cuda()\n",
    "    \n",
    "    print(\"#####################---MAE_Value---#####################\")\n",
    "    print(\"MAE=\",MAE(number=number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Normalized Cross Correlation (NCC)\n",
    "# $ NCC=\\frac{1}{n}\\sum_{x,y}\\frac{1}{\\sigma_{f} \\sigma _{f}}f(x,y)t(x,y) $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/yuta-hi/pytorch_similarity\n",
    "def NCC(number=1):\n",
    "    model = NormalizedCrossCorrelation(return_map=True) #NCC\n",
    "    \n",
    "    meanarr=list()\n",
    "\n",
    "    for s in range(number):\n",
    "        semi_ncc=0.0\n",
    "        for i,(y) in enumerate(train_loader):\n",
    "            \n",
    "            y = Variable(y).cuda()\n",
    "            #y=((y+1)/2) #normalization [0,1]\n",
    "            y = rescale_array(y, 0.0, 1.0)\n",
    "            \n",
    "            z_rand = Variable(torch.randn((BATCH_SIZE,LATENT_DIM)),volatile=True).cuda() #random vector\n",
    "            x_rand = G(z_rand) #prediction image\n",
    "            #x_rand=((x_rand+1)/2) #normalization [0,1]\n",
    "            x_rand = rescale_array(x_rand, 0.0, 1.0)\n",
    "            \n",
    "            if y.size()==x_rand.size():\n",
    "                gc, gc_map = model(x_rand, y)\n",
    "                semi_ncc+=gc.item()\n",
    "        \n",
    "        meanarr.append(semi_ncc/(i+1))\n",
    "    meanarr2=torch.tensor(meanarr)\n",
    "    \n",
    "    return('Total_mean:'+str(torch.mean(meanarr2).item())+' STD:'+str(torch.std(meanarr2).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CALC_NCC:\n",
    "    number=100\n",
    "    model_number=200000\n",
    "    G=nets(only_G=True, number=model_number).cuda()\n",
    "    print(\"#####################---NCC_Value---#####################\")\n",
    "    print(\"NCC=\",NCC(number=number))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
